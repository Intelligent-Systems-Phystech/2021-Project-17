\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{url}
\usepackage[T2A]{fontenc}	
\usepackage{ dsfont }
\usepackage{amssymb}
\usepackage[english, russian]{babel}
\usepackage{graphicx}
%\DeclareGraphicsExtensions{.pdf,.png,.jpg}
\usepackage{float}
\usepackage{natbib}
\title{Выбор согласованных моделей для построения нейроинтерфейса}
\author{Кулаков Ярослав}
\date{February 2021}
\doublespacing

\begin{document}

\maketitle




\section{Аннотация}
В работе исследуется задача построения нейро-компьютерного интерфейса (BCI). Рассматривается задача предсказания трехмерной траектории движения кисти по сигналам с коры головного мозга (ECoG). Сложность задачи состоит в том, что приходится работать с высокоразмерными и сильно скоррелированными данными. Предлагается применить методы снижения размерности исходного пространства. Для решения задачи используются линейные и нелинейные модели. Проводится анализ прогноза и латентного пространства, получаемых парой гетерогенных моделей. Эксперементальные результаты подтверждают, что предлагаемый метод улучшает качество предсказаний модели.

\section{Введение}
Нейрокомпьютерные интерфейсы предоставляют возможность интерпретации мозга, возможность получать разную информацию об активности мозга, использовать и обрабатывать ее моделями машинного обучения с целью предсказания действий или декодирования мыслей человека. Из-за высокой сложности мозга и большого количества информации, содержащейся в нем в каждый момент времени, BCI сталкивается с проблемами, такими как высокая размерность получаемых данных электроэнцефалограммы и электрокортикограммы и скоррелированности их временных рядов. Для получения нескоррелированных, но информативных признаков, решается задача снижения размерности исходного пространства.\cite{feature_selection_ecog}
В работе предлагается исследовать разные модели машинного обучения: линейные и нелинейные нейросети. Оценивается качество, устойчивость и сложность рассматриваемых моделей.  \par

В статье (Катруца, Стрижов, 2017)\cite{qpfs}  даны обширные сравнения алгоритмов снижения размерности: QPFS с LARS, Lasso, Stepwise, Ridge и отбор признаков с генетическим алгоритмом. Quadratic Programming Feature Selection (QPFS) \cite{qpfs} превосходит конкурентов и этот метод можно адаптировать для нашей задачи. Так же проводится сравнение с методами PLS, PCA, других нелинйных моделей.  При решении задачи выбора признаков, одновременно оптимизируются две задачи: минимизируется корреляция между признаками и максимизируется информативность признаков по отношению к таргету. Задача осложняется тем, что признаки и таргеты имеют разную природу. \par
В данной работе получен устойчивый пайплан модулирования сигнала в конечности от карты активности мозга, состоящий из этапов:
\begin{itemize}
    \item Построение латентного пространства меньшей размерности, с минимальной корреляцией признаков и максимальной информативностью.
    \item Построение прогностической модели в полученном пространстве.
     \item Восстановление обратной зависимости для предсказания активности мозга.
\end{itemize}

\section{Постановка задачи}
Рассматривается датасет $(X, Y).$ $ X \in \mathds{R}^{T, K}$, где $T$ --- количество временных отметок, а $K$ ---  количество электродов, используемых для снятия сигнала. $Y \in \mathds{R}^{C, T}$, где $C$ --- номер координаты в трехмерном пространстве. Данные содержат записи о траектории движения руки в 3х-мерном пространстве и ECoG сигнала. ECoG сигнал снимался с 64х электродов, частотой 1кГц. Чтобы сформировать тензор признаков, каждая эпоха ECoG была сопоставлена с временно-частотно-пространственным пространством с помощью непрерывного волнового преобразования (CWT). %ссыдка
\par
Снижение размерности. Задача состоит в поиске функций $\phi: X^{n\times m} \rightarrow X^{n\times k}$ для объектов и функции  $\psi: Y^{n\times p} \rightarrow X^{n\times q}$ для кодирования целевых переменных. Причем $k < m, q < p.$ Полученные матрицы являются матрицами представлений в латентном пространстве.
\par
 %PLS
\par
Рассматриваются линейные и нелинейные модели. Линейные модели менее подвержены проклятию размерности и слабее переобучаются, а нелинейные методы способны уловить сложные закономерности. Чтобы объединить преимущества обоих методов рассматриваются generalized linear models, additive models и их комбинация --- GAM. \par
Линейная модель задается в виде $\hat y = X^T\theta + \theta_0,$ где $X$ --- матрица объект-признаков, а $\theta$ --- вектор параметров модели. Предполагается, что истинная зависимость так же является линейной, с шумом, распределенным нормально. \par
GLM --- обобщение линейной регрессии, в котором мы можем применять разные функции к $y$, а так же предполагать разные его распределния. \par
AM --- еще один способ по внедрению нелинейности в модель. $\hat y = \theta_0 + \sum \theta_i f_i(x_i)$. \par
Используемые метрики и критерии качества: $MSE(||y-\hat y||_2^2 ), MAE(||y-\hat y||_1), MAPE(\frac{1}{n}\sum \frac{|Y_i-\hat Y_i|}{Y_i})$.  \par
Соответственно задача ставится как минимизация этих Loss-function: $L(X, Y, \Theta) \rightarrow min.$

\section{Вычислительный эксперимент}
\subsection{Цель}
Обучить базовую модель PLS на преобразованных данных и сравнить с моделью линейной регрессии. Визуализировать полученные результаты.
\subsection{Описание датасета}
Датасет состоит из 20-ти записей двух обезьян, которые пытались достать кусочек еды правой рукой. Преобразованные с помощью непрерывного волнового преобразования данные представляют собой тензор $X \in \mathds{R}^{T, K, W+1}$, где $W$ --- размерность для волновых коэффициентов преобразования. Кроме того, к данным добавлен исходная матрица матрица временных рядов для каждого датчика. $Y$ остается неизменной. Данные подготовлены Анастасией Мотренко и уже подеелны на обучающую и тестовую выборки. Обучающая выборка имеет следующую размерность: $X:(12801, 32, 27)$, где $12801$ --- количество временных отметок, $32$ --- количество электродов, $27$ --- количество частот для построения коэффициентов преобразования и еще одно значение, отвечающее напряжению на датчике при фиксированоном моменте времени и номере датчика. $Y:(12801, 3)$, соответственно для каждой отметки времени имеется три координаты позиции кисти. \par
\subsection{План}
Прежде чем применять алгоритмы сгенерируем дополнительно признаки --- экспоненциируем существующие. Такая синтезация будет полезной, так как значения признаков слабо отличаются друг от друга и алгоритму сложнее будет искать закономерности. А при экспоненциировании разницы между значениями станут существенными. После этого обучим базовую модель PLS. Опытным путем подбеерм оптимальную размерность латеннтного пространства для этого алгоритма. Посмотрим на графики предсказаний и истинных значений по всем трем координатам. Так же построим истинную и предсказанную траекторию в трехмерном пространстве.  В конце сравним с результатом работы линейной регрессии и убедимся, что применение PLS было оправданным, размерность и правда очень большая для обычной линейной регрессии.
\subsection{Выполнение}
После генерации фичей и применения алгоритма PLS получили на тестовых данных следующие предсказиния.

\begin{figure}[H]
\includegraphics[scale=0.5]{images/1.png}
\end{figure}
\begin{figure}[H]
\includegraphics[scale=0.5]{images/2.png}
\end{figure}
\begin{figure}[H]
\includegraphics[scale=0.5]{images/3.png}
\end{figure}

Посмотрим на предсказания в 3D.
\begin{figure}[H]
\includegraphics[scale=0.5]{images/4.png}
\end{figure}
И наконец, применим модель линейной регрессии.
\begin{figure}[H]
\includegraphics[scale=0.5]{images/5.png}
\end{figure}

\subsection{Результаты}
Из графиков можно сделать вывод, что уже сейчас, используя только баловый алгоритм PLS удалось определять основные закономерности и пики в движении. Стоит отметить, что особенно хорошо определялись именно резкие изменения по координатам, а когда кисть не двигалась, предсказания были не точными и шумными. Это не удивительно, ведь когда мозг посылает сигналы руке, он думает не о кординате руки, а о силе, которую надо приложить мышце, то есть по второму закону Ньютона, об ускорении руки. Иными словами, при одинаковых сигналах мозга траектория движения руки будет одинаковая, не зависимо от того, находимся ли мы в точке $(0,0,0)$ или в точке $(100,100,100)$, так что предсказывать напрямую координату по сигналам мозга не совсем правильно. Кроме того, видно, что обычная линейная регрессия не добилась хоть каких-то результатов. Таким образом имеет смысл использовать алгоритмы понижения резмерности. В будущем предполагается оценить предсказания алгоритма по функциям риска, указанных выше.

\section{Литература}



\nocite{*}
\bibliographystyle{plain}
\bibliography{references}



\end{document}
